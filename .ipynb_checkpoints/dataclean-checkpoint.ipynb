{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning and normalization of raw data\n",
    "\n",
    "In this demo, the raw data extracted by chemdataextractor_batteries will be cleaned and normalized including the following steps: removing the incorrect data records, processing compound names, and creating different versions of databases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "raw_data = []\n",
    "fileroot = 'save/raw_data.json'\n",
    "with open(fileroot, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        raw_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rawdata(raw_data):\n",
    "    \"\"\"\n",
    "    Data tables created with columns including Property, Name, Raw_value, Raw_unit, Value, Unit,\n",
    "    DOI, Title, Journal, Date, Specifier, Correctness, Tag, Info, and Warning.\n",
    "    \"\"\"\n",
    "    new_dic = {}\n",
    "    property_raw = list(raw_data.keys())[0]\n",
    "    propertyname = property_raw.split('Battery')[-1]\n",
    "    new_dic['Property'] = propertyname\n",
    "    new_dic['name'] = raw_data[property_raw]['compound']['Compound']['names']\n",
    "    new_dic['Raw_value'] = raw_data[property_raw]['raw_value']\n",
    "    new_dic['Raw_unit'] = raw_data[property_raw]['raw_units']\n",
    "    new_dic['Value'] = raw_data[property_raw]['value']\n",
    "    new_dic['Unit'] = raw_data[property_raw]['units']\n",
    "    \n",
    "    new_dic['DOI'] = raw_data['metadata']['doi']\n",
    "    new_dic['Title'] = raw_data['metadata']['title']\n",
    "    new_dic['Journal'] = raw_data['metadata']['journal']\n",
    "    new_dic['Date'] = raw_data['metadata']['date']\n",
    "    \n",
    "    if 'specifier' in raw_data[property_raw]:\n",
    "        new_dic['Specifier'] = raw_data[property_raw]['specifier']\n",
    "    else: \n",
    "        new_dic['Specifier'] = 'None'\n",
    "    new_dic['Correctness'] = 'None'\n",
    "    new_dic['Tag'] = 'CDE'\n",
    "    \n",
    "    new_dic['Info'] = {}\n",
    "    if propertyname == 'Capacity':\n",
    "        if 'current_value' in raw_data['BatteryCapacity']:\n",
    "            new_dic['Info']['current_value'] = raw_data['BatteryCapacity']['current_value']\n",
    "        if 'current_units' in raw_data['BatteryCapacity']:\n",
    "            new_dic['Info']['current_units'] = raw_data['BatteryCapacity']['current_units']\n",
    "        if 'cycle_value' in raw_data['BatteryCapacity']:\n",
    "            new_dic['Info']['cycle_value'] = raw_data['BatteryCapacity']['cycle_value']\n",
    "        if 'cycle_units' in raw_data['BatteryCapacity']:\n",
    "            new_dic['Info']['cycle_units'] = raw_data['BatteryCapacity']['cycle_units']\n",
    "    if new_dic['Info'] == {}:\n",
    "        new_dic['Info'] = \"None\"\n",
    "    if propertyname == 'Coulombic':\n",
    "        new_dic['Property'] = 'Coulombic Efficiency'\n",
    "    if 'warning' in list(raw_data.keys()):\n",
    "        new_dic['Warning'] = 'R'\n",
    "    else:\n",
    "        new_dic['Warning'] = 'None'\n",
    "            \n",
    "    return new_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the data tables as dictionaries and pandas dataframe.\n",
    "newdata = []\n",
    "for data in raw_data:\n",
    "        newdata0 = convert_rawdata(data)\n",
    "        newdata.append(newdata0)\n",
    "df = pd.DataFrame(newdata)\n",
    "df = df.drop(columns=['Value'])\n",
    "df = df.loc[df.astype(str).drop_duplicates().index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capfirst(s):\n",
    "    \"\"\"Capitalize the first letter. Remain unchanged for others.\"\"\"\n",
    "    return s[:1].upper() + s[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_value(string):\n",
    "    \"\"\"\n",
    "    Takes a string and returns a list of floats representing the string given.\n",
    "    Usage::\n",
    "        test_string = '150 to 160'\n",
    "        end_value = extract_value(test_string)\n",
    "        print(end_value) # [150., 160.]\n",
    "    :param str string: A representation of the values as a string\n",
    "    :returns: The value expressed as a list of floats of length 1 if the value had no range,\n",
    "        and as a list of floats of length 2 if it was a range.\n",
    "    :rtype: list(float)\n",
    "    \"\"\"\n",
    "    if string is None:\n",
    "        return None\n",
    "    string = string.replace(\"-\", \"-\")\n",
    "    string = string.replace(\"–\", \"-\")\n",
    "    string = string.replace(\"−\", \"-\")\n",
    "    string = string.replace(\",\", \" \")\n",
    "    string = string.split(\"±\")[0]\n",
    "    split_by_space = [r for r in re.split(' |(-)', string) if r]\n",
    "    split_by_num = []\n",
    "    for elem in split_by_space:\n",
    "        split_by_num.extend([r for r in re.split('(\\d+\\.?(?:\\d+)?)', elem) if r])\n",
    "    try:\n",
    "        if split_by_num[0] == \"-\":\n",
    "            split_by_num[0] = \"-\" + split_by_num.pop(1)\n",
    "    except:\n",
    "        pass\n",
    "    flag = 0\n",
    "    new_split_by_num = []\n",
    "    for index, value in enumerate(split_by_num):\n",
    "        if flag == 2:\n",
    "            new_split_by_num.append(split_by_num[index - 2])\n",
    "            new_split_by_num.append(split_by_num[index - 1] + value)\n",
    "            flag = 0\n",
    "        elif flag == 1 and re.match('(-?\\d+\\.?(?:\\d+)?)', value):\n",
    "            new_split_by_num.append(split_by_num[index - 1])\n",
    "            new_split_by_num.append(value)\n",
    "            flag = 0\n",
    "        elif not re.match('(-?\\d+\\.?(?:\\d+)?)', value):\n",
    "            flag += 1\n",
    "        else:\n",
    "            new_split_by_num.append(value)\n",
    "    values = []\n",
    "    for index, value in enumerate(new_split_by_num):\n",
    "        try:\n",
    "            float_val = float(value)\n",
    "            float_val = abs(float_val)\n",
    "            values.append(float_val)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return values\n",
    "\n",
    "\n",
    "def extract_conduct_number(number):\n",
    "    \"\"\"Extract conductivity value with power\"\"\"\n",
    "    if re.findall(r'(\\d+.)?\\d+ × 10( )?[−−−-]( )?\\d', number):\n",
    "        numbers = extract_value(number)\n",
    "        try:\n",
    "            extracted_value = numbers[-3] * numbers[-2] ** -numbers[-1]\n",
    "        except BaseException:\n",
    "            return False\n",
    "    elif re.findall(r'10( )?[−−−-]( )?\\d', number):\n",
    "        numbers = extract_value(number)\n",
    "        extracted_value = numbers[-2] ** -numbers[-1]\n",
    "    elif re.findall(r'(\\d+.)?\\d+ × 10\\d', number):\n",
    "        numbers = extract_value(number)\n",
    "        try:\n",
    "            extracted_value = numbers[-2] * 10 ** (numbers[-1] - 100)\n",
    "        except BaseException:\n",
    "            return False\n",
    "    elif re.findall('^10[1-9]$', number):\n",
    "        numbers = extract_value(number)\n",
    "        extracted_value = 10 ** (numbers[-1] - 100)\n",
    "    else:\n",
    "        extracted_value = extract_value(number)\n",
    "    return extracted_value\n",
    "\n",
    "\n",
    "def extract_conduct_value(string):\n",
    "    \"\"\"\n",
    "    Extract conductivity values\n",
    "    :param string:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "#     if re.match('[−−−-]? \\d (and|to|[−−−–-]) \\d', 'string'):\n",
    "#         string_list = re.split('and|to|[^10][−−−–-]]', string)\n",
    "        \n",
    "    if 'and' in string or 'to' in string or \",\" in string:\n",
    "        string_list = re.split('and|to|,', string)\n",
    "    else:\n",
    "        string_list = [string]\n",
    "    extracted_values = []\n",
    "    for number in string_list:\n",
    "        extracted_value = extract_conduct_number(number)\n",
    "        extracted_values.append(extracted_value)\n",
    "\n",
    "    extracted_values_final = []\n",
    "    for value in extracted_values:\n",
    "        if type(value) != list:\n",
    "            extracted_values_final.append(value)\n",
    "        else:\n",
    "            for value_in_list in value:\n",
    "                if value_in_list != []:\n",
    "                    extracted_values_final.append(value_in_list)      \n",
    "    return extracted_values_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw values into standard formula\n",
    "value = df.apply(lambda df: extract_value(df['Raw_value']) if df['Property'] != \"Conductivity\" else extract_conduct_value(df['Raw_value']) , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dictionary df_dic with normalized value\n",
    "df.insert(loc=4, column=\"value\", value=value, allow_duplicates=False)\n",
    "df.insert(loc=5, column='Value', value='v')\n",
    "df.insert(loc=6, column='Name', value='n')\n",
    "df_dic = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "df_dics = []\n",
    "for i, row in enumerate(df_dic):\n",
    "    name_list = [capfirst(na) for na in row['name']]\n",
    "    name = list(sorted(set(name_list), key=name_list.index))\n",
    "    value = row['value']\n",
    "    row['Type'] = 'None'\n",
    "    if len(name) == 1 and len(value) == 1:\n",
    "        row['Name'] = capfirst(name[0])\n",
    "        row['Value'] = value[0]\n",
    "        df_dics.append(row)\n",
    "    elif len(name) ==1 and len(value) >1:\n",
    "        for v in value:\n",
    "            new_row = copy.deepcopy(row)\n",
    "            new_row['Name'] = capfirst(name[0]) \n",
    "            new_row['Value'] = v\n",
    "            df_dics.append(new_row)\n",
    "    elif len(name) >1 and len(value) == 1:\n",
    "        for n in name:\n",
    "            new_row = copy.deepcopy(row)\n",
    "            new_row['Name'] = capfirst(n) \n",
    "            new_row['Value'] = value[0]\n",
    "            df_dics.append(new_row)\n",
    "    elif len(name) == len(value) and len(name)>1:\n",
    "        for index in range(len(name)):\n",
    "            new_row = copy.deepcopy(row)\n",
    "            new_row['Name'] = capfirst(name[index])\n",
    "            new_row['Value'] = value[index]\n",
    "            df_dics.append(new_row)\n",
    "    else:\n",
    "        for nindex in range(len(name)):\n",
    "            for vindex in range(len(value)):\n",
    "                new_row = copy.deepcopy(row)\n",
    "                new_row['Name'] = capfirst(name[nindex]) \n",
    "                new_row['Value'] = value[vindex]\n",
    "                df_dics.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse.material_parser import MaterialParser\n",
    "def name_normalise(chems):\n",
    "    \"\"\"\n",
    "    Normalize the chemical name as a dictionary of element names and its numbers. e.g. NaCl as {'Na':1, 'Cl':1}\n",
    "    \"\"\"\n",
    "    mp = MaterialParser(pubchem_lookup=False, verbose=False)\n",
    "    patter = r'He|Li|Be|Ne|Na|Mg|Al|Si|Cl|Ar|Ca|Sc|Ti|Cr|Mn|Fe|Co|Ni|Cu|Zn|Ga|Ge|As|Se|Br|Kr|Rb|Sr|Zr|Nb|Mo|Tc|Ru|' \\\n",
    "             r'Rh|Pd|Ag|Cd|In|Sn|Sb|Te|Xe|Cs|Ba|La|Ce|Pr|Nd|Pm|Sm|Eu|Gd|Tb|Dy|Ho|Er|Tm|Yb|Lu|Hf|Ta|Re|Os|Ir|Pt|Au|Hg' \\\n",
    "             r'|Tl|Pb|Bi|Po|At|Rn|Fr|Ra|Ac|Th|Pa|Np|Pu|Am|Cm|Bk|Cf|Es|Fm|Md|No|Lr|Rf|Db|Sg|Bh|Hs|Mt|Ds|Rg|Cn|Nh|Fl' \\\n",
    "             r'|Mc|Lv|Ts|Og|C|H|B|N|O|F|P|S|K|V|Y|I|W|U',\n",
    "    pattern = patter[0].split('|')\n",
    "\n",
    "    chem = chems.replace(' / ', '/').replace(' @ ', '@')\n",
    "    if re.compile(r'\\d/\\d').search(chem) is None and '/' in chem:\n",
    "        chem_list = chem.split('/')\n",
    "    elif re.compile(r'\\d@\\d').search(chem) is None and '@' in chem:\n",
    "        chem_list = chem.split('@')\n",
    "    else:\n",
    "        chem_list = [chem]\n",
    "    normalized_name = []\n",
    "    for cem in chem_list:\n",
    "        try:\n",
    "            parse = mp.parse_material(cem)\n",
    "            if parse['composition'] != []:\n",
    "                if parse['composition'][0]['elements'] != {}:\n",
    "                    if all(\n",
    "                            i in pattern for i in parse['composition'][0]['elements']):\n",
    "                        normalized_name.append(\n",
    "                            dict(parse['composition'][0]['elements']))\n",
    "        except BaseException:\n",
    "            continue\n",
    "    return normalized_name, chems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the reference electrode compound\n",
    "from itertools import chain\n",
    "reference_list=['Hg / Hg2Cl2', 'H2O / H2' ,'Ag / Ag2SO4','Pt / C','Hg / Hg2SO4','HgO / Hg','Hg / HgCl','AgCl / Ag','Hg / HgO','Ag / AgCl','acid','+']\n",
    "reference_list0 = [i + 'electrode' for i in reference_list]\n",
    "reference_list1 = [i + 'electrodes' for i in reference_list]\n",
    "reference = reference_list + reference_list0 + reference_list1\n",
    "chainrange0 = chain(range(40,42), range(48, 58),range(65,91),range(97,123))\n",
    "chainrange = [i for i in chainrange0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the types for each data record, including Anode, Cathode, and Electrolyte.\n",
    "new_dics = []\n",
    "for i,row in enumerate(df_dics):\n",
    "    print(row)\n",
    "    name = row['Name']\n",
    "    name = name.replace(\"composites\",\"\").replace(\"materials\", \"\").replace(\"electrodes\", \"\").replace(\"electrode\", \"\").replace(\"material\", \"\").replace(\"composite\",\"\")\n",
    "    ordletter = row['Name'][0]\n",
    "    ordletter1 = row['Name'][-1]\n",
    "    if len(name) <=3 or name.endswith('/'):\n",
    "        continue\n",
    "    if name in reference or ord(ordletter) not in chainrange or ord(ordletter1) not in chainrange:\n",
    "        continue\n",
    "    if name.endswith('anode') or name.endswith('anodes'):\n",
    "        name = \" \".join(name.split()[0:-1])\n",
    "        row['Type'] = 'Anode'\n",
    "        print(row)\n",
    "    elif name.endswith('cathode') or name.endswith('cathodes'):\n",
    "        name = \" \".join(name.split()[0:-1])\n",
    "        row['Type'] = 'Cathode'\n",
    "        print(row)\n",
    "    elif name.endswith('electrolyte') or name.endswith('electrolytes'):\n",
    "        name = \" \".join(name.split()[0:-1])\n",
    "        row['Type'] = 'Electrolyte'\n",
    "        print(row)\n",
    "    normalized_name,_ = name_normalise(name)\n",
    "    if normalized_name:\n",
    "        row['Name'] = name\n",
    "        row['Extracted_name'] = normalized_name\n",
    "        print(row)\n",
    "        new_dics.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardlise different values and units as one formal unit\n",
    "new_dics1=[]\n",
    "for dat in new_dics:\n",
    "    extract_name = dat['Extracted_name']\n",
    "    if len(extract_name)==1 and len(extract_name[0])==1:\n",
    "        continue\n",
    "    if dat['Property']=='Voltage':\n",
    "        if dat['Unit'] == 'MilliVolt^(1.0)':\n",
    "            dat['Value'] = dat['Value']/1000\n",
    "            dat['Unit'] = 'Volt^(1.0)'\n",
    "        if dat['Unit'] == 'DimensionlessUnit':\n",
    "            dat['Unit'] = 'Volt^(1.0)'\n",
    "        if dat['Unit'] != 'Volt^(1.0)':\n",
    "            continue\n",
    "            \n",
    "        if dat['Value'] > 5 or dat['Value'] < 1:\n",
    "            if dat['Warning'] == 'R':\n",
    "                dat['Warning'] = 'RL'\n",
    "            else:\n",
    "                dat['Warning'] = 'L'\n",
    "        if dat['Value'] < 7 and dat['Value'] > 0.01:\n",
    "            new_dics1.append(dat)\n",
    "            \n",
    "    if dat['Property'] == 'Capacity':\n",
    "        if dat['Unit'] == 'Ampere^(1.0) Hour^(1.0) KiloGram^(-1.0)':\n",
    "            dat['Unit'] = 'Gram^(-1.0)  Hour^(1.0)  MilliAmpere^(1.0)'\n",
    "        if dat['Unit'] ==  'Ampere^(1.0)  Gram^(-1.0)  Hour^(1.0)':\n",
    "            dat['Value'] = dat['Value']*1000\n",
    "            dat['Unit'] = 'Gram^(-1.0)  Hour^(1.0)  MilliAmpere^(1.0)'\n",
    "        if dat['Unit'] == 'Hour^(1.0)  KiloGram^(-1.0)  MilliAmpere^(1.0)':\n",
    "            dat['Value'] = dat['Value']/1000\n",
    "            dat['Unit'] = 'Gram^(-1.0)  Hour^(1.0)  MilliAmpere^(1.0)'\n",
    "            \n",
    "        if dat['Value'] > 3000 or dat['Value'] < 20:\n",
    "            if dat['Warning'] == 'R':\n",
    "                dat['Warning'] = 'RL'\n",
    "            else:\n",
    "                dat['Warning'] = 'L'\n",
    "        if dat['Value'] < 5000 and dat['Value']>0:\n",
    "            new_dics1.append(dat)\n",
    "            \n",
    "    if dat['Property'] == 'Conductivity':\n",
    "        if dat['Unit'] == 'CentiMeter^(-1.0)  MilliSiemens^(1.0)':\n",
    "            dat['Value'] = dat['Value']/1000\n",
    "            dat['Unit'] = 'CentiMeter^(-1.0)  Siemens^(1.0)'\n",
    "        if dat['Unit'] == 'Meter^(-1.0)  MilliSiemens^(1.0)':\n",
    "            dat['Value'] = dat['Value']/100000\n",
    "            dat['Unit'] = 'CentiMeter^(-1.0)  Siemens^(1.0)'\n",
    "        if dat['Unit'] != 'CentiMeter^(-1.0)  Siemens^(1.0)':\n",
    "            continue\n",
    "            \n",
    "        if dat['Value'] > 10:\n",
    "            if dat['Warning'] == 'R':\n",
    "                dat['Warning'] = 'RL'\n",
    "            else:\n",
    "                dat['Warning'] = 'L'\n",
    "        if dat['Value'] < 100.1:\n",
    "            new_dics1.append(dat)\n",
    "        \n",
    "    if dat['Property'] == 'Coulombic Efficiency':\n",
    "        if dat['Value'] < 20:\n",
    "            if dat['Warning'] == 'R':\n",
    "                dat['Warning'] = 'RL'\n",
    "            else:\n",
    "                dat['Warning'] = 'L'\n",
    "        if dat['Value'] <=100 and dat['Value']>0:\n",
    "            new_dics1.append(dat)\n",
    "    if dat['Property'] == 'Energy':\n",
    "        if dat['Unit'] == 'Gram^(-1.0)  WattHour^(1.0)':\n",
    "            dat['Value'] = dat['Value']*1000\n",
    "            dat['Unit'] = 'KiloGram^(-1.0)  WattHour^(1.0)'\n",
    "        if dat['Unit'] ==  'KiloGram^(1.0)  WattHour^(1.0)':\n",
    "            dat['Unit'] ='KiloGram^(-1.0)  WattHour^(1.0)'\n",
    "        if dat['Unit'] != 'KiloGram^(-1.0)  WattHour^(1.0)':\n",
    "            continue\n",
    "            \n",
    "        if dat['Value'] > 3000 or dat['Value'] < 100:\n",
    "            if dat['Warning'] == 'R':\n",
    "                dat['Warning'] = 'RL'\n",
    "            else:\n",
    "                dat['Warning'] = 'L'\n",
    "        if dat['Value'] <5000 and dat['Value']>0:\n",
    "            new_dics1.append(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert python dictionaries back into pandas dataframe again\n",
    "df1 = pd.DataFrame(new_dics1)\n",
    "\n",
    "cols_to_order = ['Property', 'Name', 'Value','Raw_unit','Raw_value','Unit','Extracted_name','DOI','Specifier','Tag','Warning','Type','Info']\n",
    "new_columns = cols_to_order + (df1.columns.drop(cols_to_order).tolist())\n",
    "df1 = df1[new_columns]\n",
    "\n",
    "df1 = df1.drop_duplicates(subset=['Property','Value','DOI','Name'],keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation preparation\n",
    "group = df1.groupby('Name')\n",
    "df2 = group.apply(lambda x: x['Property'].unique())\n",
    "aug_names = []\n",
    "for name0,propertylist in df2.iteritems():\n",
    "    if 'Capacity' in propertylist and 'Voltage' in propertylist and 'Energy' not in propertylist:\n",
    "        aug_names.append(name0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data augmentation for unknown energy data\n",
    "for i,aug_name in enumerate(aug_names):\n",
    "    print(i)\n",
    "    newdf = df1[df1['Name']==aug_name]\n",
    "    volt = newdf[newdf['Property']=='Voltage'].Value.mean()\n",
    "    capa = newdf[newdf['Property']=='Capacity'].Value.mean()\n",
    "    ener = volt*capa\n",
    "    add = newdf.iloc[0].copy()\n",
    "    add['Property'] = 'Energy'\n",
    "    add['Value'] = ener\n",
    "    add['Raw_value'] = str(ener)\n",
    "    add['Raw_unit'] = 'Wh/kg'\n",
    "    add['Unit'] = 'KiloGram^(-1.0)  WattHour^(1.0)'\n",
    "    add['Tag'] = 'Calculated'\n",
    "    add['DOI'], add['Specifier'], add['Warning'], add['Info'], add['Type'], add['Title'], add['Journal'], add['Date'] = 'None','None','None','None','None','None','None','None'\n",
    "    df1 = df1.append(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1[~df1['Name'].str.startswith('–')]\n",
    "df2 = df2.sort_values(by=['Name'])\n",
    "df2 = df2.drop_duplicates(subset=['Property','Value','DOI','Name'],keep='last')\n",
    "df2 = df2.sample(frac=1).reset_index(drop=True)\n",
    "df2['id']=df2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge duplicated data with same property, value, and units.\n",
    "def join(doi):\n",
    "    return ', '.join((doi))\n",
    "def unchange(item):\n",
    "    return [item.iloc[:]]\n",
    "df_merge_series = df2.copy()\n",
    "df_merge_series['Count'] = 'None'\n",
    "groups_series = df_merge_series.groupby(['Property','Name','DOI']).agg({'Count':'count','id':unchange})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_lists=groups_series[groups_series['Count']>3]['id'].values.tolist()\n",
    "series=[]\n",
    "for i in series_lists:\n",
    "    new_list = i[0].values.tolist()\n",
    "    for j in new_list:\n",
    "        series.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add series warning tag \"S\"\n",
    "for i in series:\n",
    "    if df2.iloc[i]['Warning']==\"None\":\n",
    "        df2.set_value(i,'Warning','S')\n",
    "    else:\n",
    "        warning = df2.iloc[i]['Warning']\n",
    "        df2.set_value(i,'Warning',warning+'S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other multiple warnings\n",
    "df2=df2[df2['Warning']!=\"RLS\"]\n",
    "df2=df2[df2['Warning']!=\"RS\"]\n",
    "df2 = df2.drop(columns=['id'])\n",
    "dfdic = df2.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data merge\n",
    "def join(doi):\n",
    "    return ', '.join(doi)\n",
    "def join_select(items):\n",
    "    string = ''\n",
    "    for i in items:\n",
    "        if i != \"None\":\n",
    "            string += str(i)\n",
    "            string += ', '\n",
    "    return string\n",
    "def unchange(item):\n",
    "    return item.iloc[0]\n",
    "df_merge = df2.copy()\n",
    "df_merge['Num_records'] = 'n'\n",
    "# df.groupby(['Property','Value','Name'])['DOI'].apply(', '.join).reset_index()\n",
    "groups = df_merge.groupby(['Property','Name','Value']).agg({'Raw_unit':unchange,'Raw_value':unchange,'Unit':unchange,'Num_records':'count',\"Extracted_name\":unchange,'DOI': join, \"Specifier\":join_select,  \"Tag\":unchange, \"Warning\":join_select,\"Type\":join_select,\"Info\":join_select,'Title': join, 'Journal':join, \"Date\":join,\"Correctness\":unchange})\n",
    "\n",
    "merge = groups.reset_index()\n",
    "merge = merge.drop_duplicates(subset=['Property','Value','DOI','Name'],keep='last')\n",
    "df5 = merge.sample(frac=1).reset_index(drop=True)\n",
    "merge = df5.replace([\"\"],\"None\")\n",
    "mergedic = merge.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the data records as json, csv and sqlite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('save/battery.json', 'w') as fout:\n",
    "    json.dump(dfdic, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_columns = list(df2.columns.values)\n",
    "try:\n",
    "    with open('battery.csv', 'a', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for data in dfdic:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "inps = []\n",
    "for i in dfdic:\n",
    "    tuple1 = tuple(str(i[k]) for k in i)\n",
    "    inps.append(tuple1)\n",
    "conn = sqlite3.connect('battery' + '.db')\n",
    "\n",
    "conn.execute('''CREATE TABLE BATTERY\n",
    "            (Property       TEXT,\n",
    "             Name           TEXT,\n",
    "             Value          TEXT,\n",
    "             Raw_unit       TEXT,\n",
    "             Raw_value      TEXT,\n",
    "             Unit           TEXT,\n",
    "             Extracted_name TEXT,\n",
    "             DOI            TEXT,\n",
    "             Specifier      TEXT,\n",
    "             Tag            TEXT,\n",
    "             Warning       TEXT,\n",
    "             Type          TEXT,\n",
    "             Info          TEXT,\n",
    "             Title         TEXT,\n",
    "             Journal       TEXT,\n",
    "             Date            TEXT,\n",
    "             Correctness   TEXT)''')\n",
    "\n",
    "db = conn.cursor()\n",
    "db.executemany(\"INSERT INTO BATTERY VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\", inps)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the merged data records as json, csv and sqlite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('battery_merged.json', 'w') as f:\n",
    "    json.dump(mergedic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_columns = list(merge.columns.values)\n",
    "try:\n",
    "    with open('battery_merged.csv', 'a', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for data in mergedic:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "inps = []\n",
    "for i in mergedic:\n",
    "    tuple1 = tuple(str(i[k]) for k in i)\n",
    "    inps.append(tuple1)\n",
    "conn = sqlite3.connect('battery_merged' + '.db')\n",
    "\n",
    "conn.execute('''CREATE TABLE BATTERY\n",
    "            (Property       TEXT,\n",
    "             Name           TEXT,\n",
    "             Value          TEXT,\n",
    "             Raw_unit       TEXT,\n",
    "             Raw_value      TEXT,\n",
    "             Unit           TEXT,\n",
    "             Num_records    REAL,\n",
    "             Extracted_name TEXT,\n",
    "             DOI            TEXT,\n",
    "             Specifier      TEXT,\n",
    "             Tag            TEXT,\n",
    "             Warning       TEXT,\n",
    "             Type          TEXT,\n",
    "             Info          TEXT,\n",
    "             Title         TEXT,\n",
    "             Journal       TEXT,\n",
    "             Date            TEXT,\n",
    "             Correctness   TEXT)''')\n",
    "\n",
    "db = conn.cursor()\n",
    "db.executemany(\"INSERT INTO BATTERY VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\", inps)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
